# Sort DF by ID lifespan
df = df.assign(freq=df.groupby('id')['id'].transform('count')).sort_values(by=['freq', 'id', 'timestamp'], ascending=[False, True, True])

# Padded input & output matrices ###TOO SLOW###
inputMatrix = np.zeros(shape=(numIDs, numTimestamps, numFeatures))
labelMatrix = np.zeros(shape=(numIDs, numTimestamps, 1))
for i, ID in enumerate(IDs):
    print(i)
    IDarray = df.loc[df['id'] == ID]
        for j, TS in enumerate(timestamps):
            if TS in IDarray['timestamp'].values:
                inputMatrix[i, j] = IDarray.loc[IDarray['timestamp'] == TS, [feature for feature in features]].as_matrix().flatten()
                labelMatrix[i, j] = IDarray.loc[IDarray['timestamp'] == TS, ['y']]

# Generates bacthes along 1 ID at a time
def generateBatch(IDPointer, TSPointer):
    inputs, labels = [], []
    newID = False               # ############## NEEDED?
    for i in range(Constants.batchSize):
        sequence = inputMatrix[IDPointer][TSPointer + i * Constants.sequenceLength:TSPointer + (i + 1) * Constants.sequenceLength]
        if len(sequence) == Constants.sequenceLength:
            inputs.append(sequence)
            labels.append(labelMatrix[IDPointer][TSPointer + (i + 1) * Constants.sequenceLength - 1])
        else:
            pad = np.zeros((1, numFeatures))
            for _ in range(Constants.sequenceLength - len(sequence)):
                sequence = np.concatenate((pad, sequence))
            inputs.append(sequence)
            labels.append(labelMatrix[IDPointer][-1])
            IDPointer += 1
            TSPointer = 0
            newID = True
            return inputs, labels, IDPointer, TSPointer, newID
    TSPointer += Constants.batchSize * Constants.sequenceLength
    return inputs, labels, IDPointer, TSPointer, newID

plt.scatter(range(df.shape[0]), df['fundamental_3'].values, alpha=0.1)
plt.tick_params(
    axis='x',
    which='both',
    bottom='off',
    top='off',
    labelbottom='off')
plt.title('fundamental_3 Normalised')
plt.savefig(Constants.dataDir + 'FeaturePlots/' + 'fundamental_3_normalised')

# FD histogram bins
counts, bins = np.histogram(df['y'], bins='auto')   # 564 bins out of 1,710,756 values

# auto bins -> uses np.hist
_, bins, _ = plt.hist(df['y'].loc[(df['y'] > 0) & (df['y'] < 1)], bins='auto')
plt.title("Extremes Excluded - " + str(len(bins)) + " Bins")
plt.savefig(Constants.dataDir + "Binning/ExtremesExcluded")

# Bayesian blocks
freqs_bins = astroplt.hist(df['y'], bins='blocks', ax=plt)
bins = len(freqs_bins[0])
plt.title("Bayesian Blocks - " + str(bins) + " Bins")
plt.savefig(Constants.dataDir + "Binning/BayesianBlocks_" + str(bins) + "Bins")
plt.show()

numBins = 10000
freqs = []
binStarts = []
binStart = 0
for i in range(numBins):
    binEnd = (1.0 / numBins) * (i + 1)
    freqs.append(df['y'][(df['y'] >= binStart) & (df['y'] < binEnd)].count())
    binStarts.append(binStart)
    binStart = binEnd

freqs[-1] += df['y'][df['y'] >= binEnd].count()

plt.bar(binStarts[:-1] + np.diff(binStarts) / 2, freqs[:(numBins // 2)] + freqs[(numBins // 2) + 1:], np.diff(binStarts))
plt.show()
